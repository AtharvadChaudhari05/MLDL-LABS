# -*- coding: utf-8 -*-
"""EXP2 MLDL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mfS_2NaI5drv2Wn_attLO8tJoe3P7WHl
"""

# ==========================================
# STEP 1: Upload File
# ==========================================

from google.colab import files
uploaded = files.upload()

filename = list(uploaded.keys())[0]

# ==========================================
# STEP 2: Import Libraries
# ==========================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# ==========================================
# STEP 3: Load Dataset
# ==========================================

data = pd.read_csv(filename)

print("\nColumn Names in Dataset:")
print(data.columns.tolist())


# ==========================================
# STEP 4: Automatically Detect Target Column
# ==========================================

# Assume last column is target
target_column = data.columns[-1]
print("\nDetected Target Column:", target_column)

y = data[target_column]
X = data.drop(target_column, axis=1)


# ==========================================
# STEP 5: Convert Categorical to Numeric
# ==========================================

X = pd.get_dummies(X, drop_first=True)


# ==========================================
# STEP 6: Train-Test Split
# ==========================================

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


# ==========================================
# STEP 7: Feature Scaling
# ==========================================

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# ==========================================
# STEP 8: Linear Regression
# ==========================================

lr = LinearRegression()
lr.fit(X_train, y_train)

y_pred_lr = lr.predict(X_test)

print("\n===== Linear Regression =====")
print("MSE:", mean_squared_error(y_test, y_pred_lr))
print("R2 Score:", r2_score(y_test, y_pred_lr))


# ==========================================
# STEP 9: Ridge Regression
# ==========================================

ridge = Ridge()
param_grid_ridge = {'alpha': [0.01, 0.1, 1, 10, 100]}

grid_ridge = GridSearchCV(ridge, param_grid_ridge, cv=5)
grid_ridge.fit(X_train, y_train)

best_ridge = grid_ridge.best_estimator_
y_pred_ridge = best_ridge.predict(X_test)

print("\n===== Ridge Regression =====")
print("Best Alpha:", grid_ridge.best_params_)
print("MSE:", mean_squared_error(y_test, y_pred_ridge))
print("R2 Score:", r2_score(y_test, y_pred_ridge))


# ==========================================
# STEP 10: Lasso Regression
# ==========================================

lasso = Lasso(max_iter=10000)
param_grid_lasso = {'alpha': [0.001, 0.01, 0.1, 1, 10]}

grid_lasso = GridSearchCV(lasso, param_grid_lasso, cv=5)
grid_lasso.fit(X_train, y_train)

best_lasso = grid_lasso.best_estimator_
y_pred_lasso = best_lasso.predict(X_test)

print("\n===== Lasso Regression =====")
print("Best Alpha:", grid_lasso.best_params_)
print("MSE:", mean_squared_error(y_test, y_pred_lasso))
print("R2 Score:", r2_score(y_test, y_pred_lasso))


# ==========================================
# STEP 11: Visualization
# ==========================================

plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred_lr, alpha=0.5, label="Linear")
plt.scatter(y_test, y_pred_ridge, alpha=0.5, label="Ridge")
plt.scatter(y_test, y_pred_lasso, alpha=0.5, label="Lasso")

plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs Predicted Comparison")
plt.legend()
plt.show()